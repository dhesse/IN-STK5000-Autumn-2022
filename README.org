* IN-STK 5000 - Autumn 2022

This repository consists the course [[course][IN-STK 5000]], held at
Oslo University in autumn 2022.

* Contents

** Course Description
**Course content**
Classic approaches in data analysis are based on a static (or predefined) procedure for both collecting and processing data. Modern approaches deal with the adaptive procedures which in practice almost always are used.

In this course you will learn how to design systems that adaptively collect and process data in order to make decisions autonomously or in collaboration with humans. The course applies core principles from machine learning, artificial intelligence, databases and parallel computing to real-world problems in safety, reproducibility, transparency, privacy and fairness.

**Learning outcome**
After taking the course, you will:

See adaptive data analysis holistically, as a general decision problem.
Have basic knowledge of SQL
Know how to adaptively plan data collection.
Understand when privacy is an issue and how to deal with privacy concerns.
Provide transparency by quantifying the strength of conclusions and ensuring reproducibility.
Be able to provide safety and reliability guarantees.
Have insight into issues of discrimination and fairness that can arise.
Be able to use large-scale data processing tools such as Tensor-Flow
Be able to deal with outliers, data contamination, etc.

** Literature
Book on lightweight theory and real-life examples (includes R examples too): *Doing Data Science*, Cathy O'Neil and Rachel Schutt. (https://learning.oreilly.com/library/view/doing-data-science/9781449363871/)
- 1. Introduction: What Is Data Science?
- 2. Statistical Inference, Exploratory Data Analysis, And The Data Science Process
- 3. Algorithms
- 4. Spam Filters, Naive Bayes, And Wrangling
- 5. Logistic Regression
- 7. Extracting Meaning From Data
- 8. Recommendation Engines: Building A User-Facing Data Product At Scale
- 9. Data Visualization And Fraud Detection
- 11. Causality
- 13. Lessons Learned From Data Competitions: Data Leakage And Model Evaluation
- 16. Next-Generation Data Scientists, Hubris, And Ethics

Book on lightweight theory and (many!) real-life examples with focus on failures: *The Ethical Algorithm*, Michael Kearns and Aaron Roth. (https://learning.oreilly.com/videos/the-ethical-algorithm/9781705237250/)
- privacy
- fairness
- missinterpreting and mishandling data

Book on use of Python libs: *Python Data Science Handbook, 2nd Edition*, Jake VanderPlas. (https://learning.oreilly.com/library/view/python-data-science/9781098121211/)
With this handbook, you'll learn how:
- IPython and Jupyter provide computational environments for scientists using Python
- NumPy includes the ndarray for efficient storage and manipulation of dense data arrays
- Pandas contains the DataFrame for efficient storage and manipulation of labeled/columnar data
- Matplotlib includes capabilities for a flexible range of data visualizations
- Scikit-learn helps you build efficient and clean Python implementations of the most important and established machine learning algorithms 

Book on use of Python libs: *Python for Data Analysis, 2nd Edition*, Wes McKinney. (https://learning.oreilly.com/library/view/python-for-data/9781491957653/)
Content:
- Use the IPython shell and Jupyter notebook for exploratory computing
- Learn basic and advanced features in NumPy (Numerical Python)
- Get started with data analysis tools in the pandas library
- Use flexible tools to load, clean, transform, merge, and reshape data
- Create informative visualizations with matplotlib
- Apply the pandas groupby facility to slice, dice, and summarize datasets
- Analyze and manipulate regular and irregular time series data
- Learn how to solve real-world data analysis problems with thorough, detailed examples

** Lectures

*** Lecture 1 - Data-based decision making

 - What is data-based decision making?
 - Why data-based decision making?
   - Industry perspective
     - What is digitalization?
       - Some examples
     - Why do we talk about digitalization now?
   - Three vs of big data
 - Methods for data-based deciion making
   - Machine learning
   - Alternatives to machine learning
 - Limitations and challenges
   - Model interpretability/explainability
   - Privacy
   - Fairness
   - Scarcity or abundance of data

** Topics

*** Introduction

*** Tools of the trade part 1 - Python, Jupyter, Pandas

The aim here is merely to get everyone on the same page. ~1-2
lectures.

- Python - Data Science's favourite programming language
- Jupyter - Notebooks
- Pandas - Industry Standard Data Analysis

*** Data and Data Quality

With the use of the tools covered in the first part, we can now look
at data and its properties and implications for data driven decision
making. The project can now already start by looking at the data and
its basic properties.

**** Basics

- Targets, what are we interested in?
- Correlation

**** Data collection

- Caveats and challenges

**** Privacy

- Sensitive variables
- GDPR
- [ ] Should we cover everything including differential privacy here,
  or do a later deep dive?

**** Outliers, Data Contamination, Fraud Detection

- Basic definitions, what is an outlier and how to identify them
  - In particular, what makes estimating tails of a distribution hard?
- Reasons for the presence or absence of outliers
- Advanced methods for outlier detection
  - Such as clustering + outlier detection, autoencoders
  - Benford's Law, fraud detection


*** Tools of the trade part 2 - Scikit-learn, Tensorflow

- Scikit-learn - Industry Standard Machine Learning Package
- Tensorflow - Accelerated Neural Networks and Bayesian Modeling


*** Beyond Machine Learning - Decision Making

- Confidence intervals, uncertainty
- Bayesian models
- Reliability and reproducibility
- Multi-armed bandits (?)

*** 'Big data' Tools: Apache Spark, Apache Airflow 

- Why do we need specific tools for large data sets?
  - What is a large data set?
- How do those tools deal with large data sets?
  - Example: Map Reduce
- Apache Spark - Big Data Machine Learning
- Apache Airflow - Model
  
*** Challenges

- Model interpretability/explainability
- Fairness
- Scarcity or abundance of data


#+LINK: course https://www.uio.no/studier/emner/matnat/ifi/IN-STK5000/index-eng.html
